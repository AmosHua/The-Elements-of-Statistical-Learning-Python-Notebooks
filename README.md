# "The Elements of Statistical Learning" Notebooks
Reproducing all examples from the "The Elements of Statistical Learning" by Trevor Hastie, Robert Tibshirani and Jerome Friedman with Python and its popular libraries: 
**numpy**, **math**, **scipy**, **sklearn**, **pandas**, **tensorflow**, **matplotlib**.

## Examples
Kindly find documented Jupyter Notebooks in [examples](https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/tree/master/examples) folder:
### [examples/Mixture.ipynb](https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Mixture.ipynb) (Gaussian Mixture Simulation)
Solving a classification problem with:
1. Optimal bayes decision boundary construction
2. Linear regression
3. Nearest-neighbor
4. Logistic regression with natural cubic spline basis expansion
5. Neural networks
6. Support vector machines
7. Prototypes and nearest-neighbors
### [examples/Prostate Cancer.ipynb](https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Prostate%20Cancer.ipynb) (Prostate Cancer)
Solving a regression problem with:
1. Ordinary least squares
2. Ridge, lasso
3. Principal components regression
4. Partial least squares
5. Best subset regression
